{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed ML Pipeline: Ray Data Processing + Kubeflow Training Demo\n",
    "\n",
    "This notebook demonstrates how to combine Ray's distributed data processing with kubeflow-training SDK for end-to-end ML pipelines using IBM Granite models.\n",
    "\n",
    "\n",
    "### Distributed Data Processing with Synthetic Data Generation + Training\n",
    "```\n",
    "Phase 1: Ray Data Processing (CodeFlare SDK)\n",
    "GSM8K â†’   Ray Cluster â†’    Synthetic Data Generation\n",
    "(7.5K)   (Distributed)   (Ray Multi-worker ~ 50K+ samples)\n",
    "\n",
    "Phase 2: Distributed Training (kubeflow-training SDK)  \n",
    "Synthetic Dataset â†’ PyTorchJob â†’ Fine-tune Granite Model\n",
    "(50K+ samples)      (Multi-node)   (LoRA adapters)\n",
    "```\n",
    "\n",
    "### Features Demonstrated\n",
    "\n",
    "**Phase 1: Ray Data Processing**\n",
    "- **CodeFlare SDK**: Ray cluster deployment and management on Kubernetes\n",
    "- **Ray Job Submission**: Distributed synthetic data generation using Ray workers\n",
    "\n",
    "**Phase 2: Distributed Training**  \n",
    "- **kubeflow-training SDK**: PyTorchJob creation and management\n",
    "- **TRL + PEFT**: Modern fine-tuning with LoRA adapters\n",
    "- **Distributed Training**: Multi-node GPU coordination \n",
    "\n",
    "### Prerequisites\n",
    "- Red Hat OpenShift AI installed\n",
    "- NVIDIA and Node Feature Discovery Operator installed\n",
    "- CodeFlare and Kubeflow Training operator (KFTO-V1) enabled/managed\n",
    "- A persistent shared storage with RWX(ReadWriteMany) access.\n",
    "    - Workbench Notebook pod: `/opt/app-root/src/shared`\n",
    "    - RayCluster pods : `/shared`\n",
    "    - PyTorchJob pods : `/shared`\n",
    "\n",
    "### References\n",
    "- [CodeFlare SDK](https://github.com/project-codeflare/codeflare-sdk): Kubernetes-native distributed computing\n",
    "- [Ray Documentation](https://docs.ray.io/): Distributed computing framework\n",
    "- [kubeflow-training SDK](https://github.com/kubeflow/training-operator): Kubernetes-native ML training\n",
    "- [IBM Granite Models](https://huggingface.co/ibm-granite/granite-3.1-2b-instruct): Enterprise LLM family\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Ray Cluster using CodeFlare SDK\n",
    "\n",
    "Configure and deploy the Ray cluster for distributed data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Ray cluster using CodeFlare SDK\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication\n",
    "import time\n",
    "\n",
    "token=\"\"\n",
    "api_server=\"\"\n",
    "\n",
    "# Authenticate with the cluster (replace with your credentials)\n",
    "auth = TokenAuthentication(\n",
    "    token=token,\n",
    "    server=api_server,\n",
    "    skip_tls=False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml resources loaded for test1-cluster\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b91a41cb199442c90a61d7b726a0108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Cluster Apply', icon='play', style=ButtonStyle(), tooltip='Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172feab955df4707b1010bc41368ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ray Cluster Configuration:\n",
      "   Name: test1-cluster\n",
      "   Workers: 1\n",
      "   Worker Resources: 1CPU, 10G RAM, {} GPU\n",
      "   Image: quay.io/rhoai/ray:2.35.0-py311-cu121-torch24-fa26\n"
     ]
    }
   ],
   "source": [
    "# Configure Ray cluster for distributed synthetic data generation\n",
    "from kubernetes.client.models import V1Volume, V1VolumeMount, V1PersistentVolumeClaimVolumeSource\n",
    "\n",
    "ray_cluster = Cluster(ClusterConfiguration(\n",
    "    name=\"test1-cluster\",\n",
    "    num_workers=1,  # 2 workers for distributed processing\n",
    "    # Head node configuration\n",
    "    head_cpu_requests=1,\n",
    "    head_cpu_limits=2,\n",
    "    head_memory_requests=8,\n",
    "    head_memory_limits=16,    \n",
    "    # Worker node configuration  \n",
    "    worker_cpu_requests=1,\n",
    "    worker_cpu_limits=2,\n",
    "    worker_memory_requests=10,\n",
    "    worker_memory_limits=20,\n",
    "    # UnComment in case of using accelerators for RayCluster\n",
    "    # worker_extended_resource_requests={'nvidia.com/gpu': 1},\n",
    "    # Ray runtime image\n",
    "    image=\"quay.io/rhoai/ray:2.35.0-py311-cu121-torch24-fa26\",\n",
    "    # Volume mount - Shared PVC storage with RWX peermissions\n",
    "    volume_mounts=[\n",
    "        V1VolumeMount(\n",
    "            name=\"shared\",\n",
    "            mount_path=\"/shared\"\n",
    "        )\n",
    "    ],\n",
    "    volumes=[\n",
    "        V1Volume(\n",
    "            name=\"shared\",\n",
    "            persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "                claim_name=\"shared\"\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "))\n",
    "\n",
    "print(\" Ray Cluster Configuration:\")\n",
    "print(f\"   Name: {ray_cluster.config.name}\")\n",
    "print(f\"   Workers: {ray_cluster.config.num_workers}\")\n",
    "print(f\"   Worker Resources: {ray_cluster.config.worker_cpu_requests}CPU, {ray_cluster.config.worker_memory_requests} RAM, {ray_cluster.config.worker_extended_resource_requests} GPU\")\n",
    "print(f\"   Image: {ray_cluster.config.image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Cluster: 'test1-cluster' has successfully been applied. For optimal resource management, you should delete this Ray Cluster when no longer in use.\n"
     ]
    }
   ],
   "source": [
    "# Deploy the Ray cluster\n",
    "ray_cluster.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for requested resources to be set up...\n",
      "Requested cluster is up and running!\n",
      "Dashboard is ready!\n",
      "Ray cluster is ready!\n"
     ]
    }
   ],
   "source": [
    "# Wait for Ray cluster to be ready\n",
    "ray_cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Cluster: 'test1-cluster' has successfully been deleted\n"
     ]
    }
   ],
   "source": [
    "ray_cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                       </span><span style=\"font-weight: bold; font-style: italic\"> ðŸš€ CodeFlare Cluster Details ðŸš€</span><span style=\"font-style: italic\">                       </span>\n",
       "<span style=\"font-weight: bold\">                                                                              </span>\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #008000; font-weight: bold\">Name</span>                                                                   â”‚ \n",
       " â”‚   <span style=\"font-weight: bold; text-decoration: underline\">test1-cluster</span>                                              Active âœ…   â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚   <span style=\"font-weight: bold\">URI:</span> ray://test1-cluster-head-svc.abdhumal-test.svc:10001              â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚   <a href=\"\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">DashboardðŸ”—</span></a>                                                            â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚  <span style=\"font-style: italic\">                     Cluster Resources                     </span>             â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®              â”‚ \n",
       " â”‚   â”‚ <span style=\"font-weight: bold\"> # Workers </span> â”‚  â”‚ <span style=\"font-weight: bold\"> Memory      CPU         GPU        </span> â”‚              â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚              â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\"> 1         </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\"> 10G~20G    </span><span style=\"color: #800080; text-decoration-color: #800080\"> 1~2         0          </span> â”‚              â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚              â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯              â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                       \u001b[0m\u001b[1;3m ðŸš€ CodeFlare Cluster Details ðŸš€\u001b[0m\u001b[3m                       \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m                                                                            \u001b[0m\u001b[1m \u001b[0m\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   \u001b[1;37;42mName\u001b[0m                                                                   â”‚ \n",
       " â”‚   \u001b[1;4mtest1-cluster\u001b[0m                                              Active âœ…   â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚   \u001b[1mURI:\u001b[0m ray://test1-cluster-head-svc.abdhumal-test.svc:10001              â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚   \u001b]8;id=928213;\u001b\\\u001b[4;34mDashboardðŸ”—\u001b[0m\u001b]8;;\u001b\\                                                            â”‚ \n",
       " â”‚                                                                          â”‚ \n",
       " â”‚  \u001b[3m                     Cluster Resources                     \u001b[0m             â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®              â”‚ \n",
       " â”‚   â”‚ \u001b[1m \u001b[0m\u001b[1m# Workers\u001b[0m\u001b[1m \u001b[0m â”‚  â”‚ \u001b[1m \u001b[0m\u001b[1mMemory    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCPU       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mGPU       \u001b[0m\u001b[1m \u001b[0m â”‚              â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚              â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m1        \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m10G~20G   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m1~2       \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m0         \u001b[0m\u001b[35m \u001b[0m â”‚              â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚              â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯              â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RayCluster(name='test1-cluster', status=<RayClusterStatus.READY: 'ready'>, head_cpu_requests=1, head_cpu_limits=2, head_mem_requests='8G', head_mem_limits='16G', num_workers=1, worker_mem_requests='10G', worker_mem_limits='20G', worker_cpu_requests=1, worker_cpu_limits=2, namespace='abdhumal-test', dashboard='', worker_extended_resources={}, head_extended_resources={})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray job client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Job Submission Client\n",
    "client = ray_cluster.job_client\n",
    "print(\"Ray job client initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Ray Job for Synthetic Data Generation\n",
    "\n",
    "Submit the synthetic data generation function to the Ray cluster:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray job submitted with ID: raysubmit_aKg8ifY1BQyCtpzM\n"
     ]
    }
   ],
   "source": [
    "# Submit the Ray job\n",
    "submission_id = client.submit_job(\n",
    "    entrypoint=\"python ray_sdg_job.py\",\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            'HF_HOME': '/shared/cache',\n",
    "            'HF_DATASETS_CACHE': '/shared/cache/datasets',\n",
    "            'TRANSFORMERS_CACHE': '/shared/cache/transformers',\n",
    "            'TOKENIZERS_PARALLELISM': 'false',\n",
    "        },\n",
    "        'pip': [\n",
    "            'ray[data]>=2.8.0',\n",
    "            'transformers>=4.36.0',\n",
    "            'torch>=2.0.0', \n",
    "            'datasets>=2.14.0',\n",
    "            'accelerate>=0.24.0'\n",
    "        ],\n",
    "        'working_dir': './',\n",
    "        \"excludes\": [\"*.ipynb\", \"*.md\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Ray job submitted with ID: {submission_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop/Delete any running jobs\n",
    "# client.stop_job(submission_id)\n",
    "\n",
    "client.delete_job(submission_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Ray Cluster\n",
    "\n",
    "Clean up the Ray cluster resources (following ray_finetune_llm_deepspeed.ipynb pattern):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup Ray cluster (following ray_finetune_llm_deepspeed.ipynb pattern)\n",
    "print(\" Cleaning up Ray cluster...\")\n",
    "\n",
    "# Tear down the Ray cluster\n",
    "ray_cluster.down()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Transition: Ray â†’ kubeflow-training\n",
    "\n",
    "The synthetic dataset generated by Ray is now ready for distributed training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify synthetic data is ready for training\n",
    "import os\n",
    "import json\n",
    "\n",
    "data_path = \"/shared/datasets/synthetic_dataset.json\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        dataset_info = json.load(f)\n",
    "    \n",
    "    print(\"Synthetic dataset ready for training!\")\n",
    "    print(f\"   Train samples: {len(dataset_info.get('train', []))}\")\n",
    "    print(f\"   Test samples: {len(dataset_info.get('test', []))}\")\n",
    "    print(f\"   Quality threshold: {dataset_info.get('metadata', {}).get('quality_threshold', 'N/A')}\")\n",
    "    print(f\"   Generated by: {dataset_info.get('metadata', {}).get('model_used', 'Local Granite')}\")\n",
    "    print(f\"   Data location: {data_path}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    if dataset_info.get('train'):\n",
    "        sample = dataset_info['train'][0]\n",
    "        print(f\"\\n Sample synthetic problem:\")\n",
    "        print(f\"   Question: {sample.get('question', '')[:100]}...\")\n",
    "        print(f\"   Answer: {sample.get('answer', '')[:100]}...\")\n",
    "        \n",
    "    print(f\"\\nTransitioning to Phase 2: Distributed Training with kubeflow-training SDK\")\n",
    "    \n",
    "else:\n",
    "    print(\"Synthetic dataset not found!\")\n",
    "    print(\"   Please run the Ray data processing phase first.\")\n",
    "    print(f\"   Expected location: {data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Configuration using kubeflow-training SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml parameters\n",
    "\n",
    "# Model configuration\n",
    "model_name_or_path: ibm-granite/granite-3.1-2b-instruct\n",
    "model_revision: main\n",
    "torch_dtype: bfloat16\n",
    "attn_implementation: flash_attention_2\n",
    "use_liger: false\n",
    "\n",
    "# PEFT / LoRA configuration\n",
    "use_peft: true\n",
    "lora_r: 16\n",
    "lora_alpha: 8\n",
    "lora_dropout: 0.05\n",
    "lora_target_modules: [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "lora_modules_to_save: []\n",
    "\n",
    "# QLoRA (BitsAndBytes)\n",
    "load_in_4bit: false\n",
    "load_in_8bit: false\n",
    "\n",
    "# Dataset configuration (synthetic data from Ray preprocessing)\n",
    "dataset_name: synthetic_gsm8k\n",
    "dataset_config: main\n",
    "dataset_train_split: train\n",
    "dataset_test_split: test\n",
    "dataset_text_field: text\n",
    "dataset_kwargs:\n",
    "  add_special_tokens: false\n",
    "  append_concat_token: false\n",
    "\n",
    "# SFT configuration\n",
    "max_seq_length: 1024\n",
    "dataset_batch_size: 1000\n",
    "packing: false\n",
    "\n",
    "# Training hyperparameters\n",
    "num_train_epochs: 3\n",
    "per_device_train_batch_size: 8\n",
    "per_device_eval_batch_size: 8\n",
    "auto_find_batch_size: false\n",
    "eval_strategy: epoch\n",
    "\n",
    "# Precision and optimization\n",
    "bf16: true\n",
    "tf32: false\n",
    "learning_rate: 2.0e-4\n",
    "warmup_steps: 10\n",
    "lr_scheduler_type: inverse_sqrt\n",
    "optim: adamw_torch_fused\n",
    "max_grad_norm: 1.0\n",
    "seed: 42\n",
    "\n",
    "# Gradient settings\n",
    "gradient_accumulation_steps: 1\n",
    "gradient_checkpointing: false\n",
    "gradient_checkpointing_kwargs:\n",
    "  use_reentrant: false\n",
    "\n",
    "# FSDP for distributed training\n",
    "fsdp: \"full_shard auto_wrap\"\n",
    "fsdp_config:\n",
    "  activation_checkpointing: true\n",
    "  cpu_ram_efficient_loading: false\n",
    "  sync_module_states: true\n",
    "  use_orig_params: true\n",
    "  limit_all_gathers: false\n",
    "\n",
    "# Checkpointing and logging\n",
    "save_strategy: epoch\n",
    "save_total_limit: 1\n",
    "resume_from_checkpoint: false\n",
    "log_level: warning\n",
    "logging_strategy: steps\n",
    "logging_steps: 1\n",
    "report_to:\n",
    "- tensorboard\n",
    "\n",
    "output_dir: /tmp/granite-3.1-2b-instruct-synthetic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure kubeflow-training Client\n",
    "\n",
    "Set up the kubeflow-training SDK client following the sft.ipynb pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure kubeflow-training client (following sft.ipynb pattern)\n",
    "from kubernetes import client\n",
    "from kubeflow.training import TrainingClient\n",
    "from kubeflow.training.models import V1Volume, V1VolumeMount, V1PersistentVolumeClaimVolumeSource\n",
    "\n",
    "configuration = client.Configuration()\n",
    "configuration.host = api_server\n",
    "configuration.api_key = {\"authorization\": f\"Bearer {token}\"}\n",
    "# Un-comment if your cluster API server uses a self-signed certificate or an un-trusted CA\n",
    "# configuration.verify_ssl = False\n",
    "\n",
    "api_client = client.ApiClient(configuration)\n",
    "training_client = TrainingClient(client_configuration=api_client.configuration)\n",
    "\n",
    "print(\"kubeflow-training client configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Job using kubeflow-training SDK\n",
    "\n",
    "Create and submit the distributed training job following the sft.ipynb pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit PyTorchJob using granite_training.py script\n",
    "from kft_granite_training import main\n",
    "\n",
    "job = training_client.create_job(\n",
    "    job_kind=\"PyTorchJob\",\n",
    "    name=\"test1-training\",\n",
    "    \n",
    "    # Use script file instead of function import\n",
    "    train_func=\"main\",\n",
    "    \n",
    "    # Pass YAML parameters as config\n",
    "    parameters=parameters,\n",
    "    \n",
    "    # Distributed training configuration\n",
    "    num_workers=2,\n",
    "    num_procs_per_worker=1,\n",
    "    resources_per_worker={\n",
    "        \"nvidia.com/gpu\": 1,  # Uncomment for GPU training\n",
    "\n",
    "        \"memory\": \"16Gi\",\n",
    "        \"cpu\": 4,\n",
    "    }    \n",
    "    base_image=\"quay.io/modh/training:py311-cuda124-torch251\",\n",
    "    \n",
    "    # Environment variables for training\n",
    "    env_vars={\n",
    "        # HuggingFace configuration - use shared storage\n",
    "        \"HF_HOME\": \"/shared/cache\",\n",
    "        \"HF_DATASETS_CACHE\": \"/shared/cache/datasets\",\n",
    "        \"TRANSFORMERS_CACHE\": \"/shared/cache/transformers\",\n",
    "        \"TOKENIZERS_PARALLELISM\": \"false\",\n",
    "        \n",
    "        # Training configuration\n",
    "        \"PYTHONUNBUFFERED\": \"1\",\n",
    "        \"NCCL_DEBUG\": \"INFO\",\n",
    "    },\n",
    "    \n",
    "    # Package dependencies\n",
    "    packages_to_install=[\n",
    "        \"transformers>=4.36.0\",\n",
    "        \"trl>=0.7.0\",\n",
    "        \"datasets>=2.14.0\",\n",
    "        \"peft>=0.6.0\",\n",
    "        \"accelerate>=0.24.0\",\n",
    "        \"torch>=2.0.0\",\n",
    "    ],\n",
    "    volumes=[\n",
    "        V1Volume(\n",
    "            name=\"shared\",\n",
    "            persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(claim_name=\"shared\")\n",
    "        ),\n",
    "    ],\n",
    "    volume_mounts=[\n",
    "        V1VolumeMount(name=\"shared\", mount_path=\"/shared\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"PyTorchJob '{job.metadata.name}' submitted successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Training Job\n",
    "\n",
    "Follow the training progress and logs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training job logs (following sft.ipynb pattern)\n",
    "training_client.get_job_logs(\n",
    "    name=\"test1-training\",\n",
    "    job_kind=\"PyTorchJob\",\n",
    "    follow=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the Training Job\n",
    "training_client.delete_job(\"test1-training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
